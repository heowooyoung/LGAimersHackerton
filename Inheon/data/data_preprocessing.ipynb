{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(df, describe_type):\n",
    "    if describe_type == 'describe' or describe_type == None:\n",
    "        print(df.describe())\n",
    "    elif describe_type == 'info':\n",
    "        print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_delete_with_threshold(df, threshold):\n",
    "    missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "    columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "    cleaned_df = df.drop(columns = columns_to_drop)\n",
    "    print('Following columns are going to drop:')\n",
    "    print(columns_to_drop)\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_train(df):\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True) # 최빈값\n",
    "\n",
    "    return df, num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_test(df, num_cols, cat_cols):\n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace = True)\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].mode()[0], inplace = True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_target_type(df):\n",
    "    if df['target'].dtype != 'int':\n",
    "        print('Changing the target type...')\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['target'] = label_encoder.fit_transform(df['target'])\n",
    "        print(f'Changed target type = {df['target'].dtype}')\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print('target is int')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_categorical_data(train_df, test_df):\n",
    "    train_df = train_df.drop(['Workorder_Dam', 'Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'], axis = 1)\n",
    "    test_df_no_id = test_df.drop(['Set ID', 'Workorder_Dam', 'Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'], axis = 1)\n",
    "    cat_cols = train_df.select_dtypes(include=['object']).columns\n",
    "    print(cat_cols)\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        train_df[col] = label_encoder.fit_transform(train_df[col].astype(str))\n",
    "        test_df[col] = label_encoder.transform(test_df_no_id[col].astype(str))\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_processing(train_df, test_df):\n",
    "    num_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    num_cols = num_cols[num_cols != 'target']\n",
    "\n",
    "    for col in num_cols:\n",
    "        Q1 = train_df[col].quantile(0.25)\n",
    "        Q3 = train_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        train_df[col] = train_df[col].apply(lambda x: lower_bound if x < lower_bound else x)\n",
    "        train_df[col] = train_df[col].apply(lambda x: upper_bound if x > upper_bound else x)\n",
    "        \n",
    "        test_df[col] = test_df[col].apply(lambda x: lower_bound if x < lower_bound else x)\n",
    "        test_df[col] = test_df[col].apply(lambda x: upper_bound if x > upper_bound else x)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_processing(train_df, test_df, scaler):\n",
    "    num_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    num_cols = num_cols[num_cols != 'target']\n",
    "\n",
    "    train_df_copy = train_df.copy()\n",
    "    test_df_copy = test_df.drop('Set ID', axis = 1).copy()\n",
    "    train_df_copy[num_cols] = scaler.fit_transform(train_df_copy[num_cols])\n",
    "    test_df_copy[num_cols] = scaler.transform(test_df_copy[num_cols])\n",
    "\n",
    "    return train_df_copy, test_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, test_size = None):\n",
    "    X = df.drop('target', axis = 1)\n",
    "    y = df['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X, y):\n",
    "    smote = SMOTE(random_state = 42)\n",
    "    # smote = SMOTENC(random_state=42)\n",
    "    \n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    X_resampled_df = pd.DataFrame(X_resampled)\n",
    "    y_resampled_df = pd.DataFrame(y_resampled, columns = ['target'])\n",
    "\n",
    "    oversampled_df = pd.concat([X_resampled_df, y_resampled_df], axis = 1)\n",
    "\n",
    "    return oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_transform(X, y, model):\n",
    "    fitted_model = model.fit(X, y)\n",
    "\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_csv(df, file_name):\n",
    "    df.to_csv(file_name, index = False)\n",
    "    print(f'Data Saved as {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    print('Accuracy:', accuracy_score(y, y_pred))\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(X_train, X_test, y_train):\n",
    "    k_best_features = int(0.2 * X_train.shape[1])\n",
    "    selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    return X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(k, X, y, model):\n",
    "    k = k\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_fold_train, X_fold_val = X[train_index], X[val_index]\n",
    "        y_fold_train, y_fold_val = y[train_index], y[val_index]\n",
    "\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    joblib.dump(model, model_name +'.pkl')\n",
    "    print(f'모델이 {model_name + '.pkl'}로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_one_unique_column(df):\n",
    "    columns_to_drop = df.columns[df.nunique() <= 1]\n",
    "    df_cleaned = df.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ml_pipeline(df, model_name, model):\n",
    "#     X = df.drop('target', axis = 1)\n",
    "#     y = df['target']\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "#     k_best_faetures = int(0.2 * X_train.shape[1])\n",
    "#     selector = SelectKBest(score_func = f_classif, k = k_best_faetures)\n",
    "#     X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "#     X_test_selected = selector.transform(X_test)\n",
    "\n",
    "#     k = 5\n",
    "#     kf = KFold(n_splits=k, shuffle = True, random_state=42)\n",
    "\n",
    "#     for train_index, val_index in kf.split(X_selected):\n",
    "#         X_fold_train, X_fold_val = X_selected[train_index], X_selected[val_index]\n",
    "#         y_fold_train, y_fold_val = y[train_index], y[val_index]\n",
    "    \n",
    "#         model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     joblib.dump(model, model_name+'.pkl')\n",
    "#     print(f\"모델이 {model_name+'.pkl'}로 저장되었습니다.\")\n",
    "\n",
    "#     loaded_model = joblib.load(model_name+'.pkl')\n",
    "\n",
    "#     y_test_pred = loaded_model.predict(X_)\n",
    "\n",
    "#     print(f'Training {model_name}...')\n",
    "#     y_pred = cross_val_predict(model, X_selected, y, cv = kf)\n",
    "#     accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "#     print(f\"{k}-fold 교차 검증 결과 (정확도): {accuracy}\")\n",
    "#     print(classification_report(y, y_pred))\n",
    "#     print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "#     return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_file(r'D:\\LGAimers\\Hackerton\\Inheon\\data\\train.csv')\n",
    "test_df = read_file(r'D:\\LGAimers\\Hackerton\\Inheon\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        127\n",
       "1          1\n",
       "2         73\n",
       "3          1\n",
       "4          1\n",
       "        ... \n",
       "40501      1\n",
       "40502    197\n",
       "40503     27\n",
       "40504      1\n",
       "40505      1\n",
       "Name: Receip No Collect Result_Dam, Length: 40506, dtype: int64"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Receip No Collect Result_Dam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 464 entries, Wip Line_Dam to target\n",
      "dtypes: float64(350), int64(77), object(37)\n",
      "memory usage: 143.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 465 entries, Set ID to target\n",
      "dtypes: float64(351), int64(77), object(37)\n",
      "memory usage: 61.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "describe_data(train_df, 'info')\n",
    "describe_data(test_df, 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\InheonChoi\\AppData\\Local\\Temp\\ipykernel_23604\\156735883.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df = train_df.replace('OK', np.nan)\n",
      "C:\\Users\\InheonChoi\\AppData\\Local\\Temp\\ipykernel_23604\\156735883.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df = test_df.replace('OK', np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 464 entries, Wip Line_Dam to target\n",
      "dtypes: float64(362), int64(77), object(25)\n",
      "memory usage: 143.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 465 entries, Set ID to target\n",
      "dtypes: float64(363), int64(77), object(25)\n",
      "memory usage: 61.6+ MB\n",
      "None\n",
      "Following columns are going to drop:\n",
      "Index(['Insp Judge Code_Dam', 'CURE END POSITION X Unit Time_Dam',\n",
      "       'CURE END POSITION X Judge Value_Dam',\n",
      "       'CURE END POSITION Z Unit Time_Dam',\n",
      "       'CURE END POSITION Z Judge Value_Dam',\n",
      "       'CURE END POSITION Θ Unit Time_Dam',\n",
      "       'CURE END POSITION Θ Judge Value_Dam', 'CURE SPEED Unit Time_Dam',\n",
      "       'CURE SPEED Judge Value_Dam', 'CURE STANDBY POSITION X Unit Time_Dam',\n",
      "       ...\n",
      "       'Machine Tact time Unit Time_Fill2',\n",
      "       'Machine Tact time Judge Value_Fill2', 'PalletID Unit Time_Fill2',\n",
      "       'PalletID Judge Value_Fill2', 'Production Qty Unit Time_Fill2',\n",
      "       'Production Qty Judge Value_Fill2', 'Receip No Unit Time_Fill2',\n",
      "       'Receip No Judge Value_Fill2', 'WorkMode Unit Time_Fill2',\n",
      "       'WorkMode Judge Value_Fill2'],\n",
      "      dtype='object', length=294)\n",
      "Following columns are going to drop:\n",
      "Index(['Insp Judge Code_Dam', 'CURE END POSITION X Unit Time_Dam',\n",
      "       'CURE END POSITION X Judge Value_Dam',\n",
      "       'CURE END POSITION Z Unit Time_Dam',\n",
      "       'CURE END POSITION Z Judge Value_Dam',\n",
      "       'CURE END POSITION Θ Unit Time_Dam',\n",
      "       'CURE END POSITION Θ Judge Value_Dam', 'CURE SPEED Unit Time_Dam',\n",
      "       'CURE SPEED Judge Value_Dam', 'CURE STANDBY POSITION X Unit Time_Dam',\n",
      "       ...\n",
      "       'Machine Tact time Judge Value_Fill2', 'PalletID Unit Time_Fill2',\n",
      "       'PalletID Judge Value_Fill2', 'Production Qty Unit Time_Fill2',\n",
      "       'Production Qty Judge Value_Fill2', 'Receip No Unit Time_Fill2',\n",
      "       'Receip No Judge Value_Fill2', 'WorkMode Unit Time_Fill2',\n",
      "       'WorkMode Judge Value_Fill2', 'target'],\n",
      "      dtype='object', length=295)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 170 entries, Wip Line_Dam to target\n",
      "dtypes: float64(72), int64(77), object(21)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 170 entries, Set ID to WorkMode Collect Result_Fill2\n",
      "dtypes: float64(72), int64(77), object(21)\n",
      "memory usage: 22.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.replace('OK', np.nan)\n",
    "test_df = test_df.replace('OK', np.nan)\n",
    "describe_data(train_df, 'info')\n",
    "describe_data(test_df, 'info')\n",
    "missing_values_delete_train_df = missing_values_delete_with_threshold(train_df, 50.0)\n",
    "missing_values_delete_test_df = missing_values_delete_with_threshold(test_df, 50.0)\n",
    "describe_data(missing_values_delete_train_df, 'info')\n",
    "describe_data(missing_values_delete_test_df, 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Set ID'}"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(missing_values_delete_test_df.columns) - set(missing_values_delete_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Insp. Seq No._Dam', 'CURE END POSITION X Collect Result_Dam',\n",
      "       'CURE END POSITION Z Collect Result_Dam',\n",
      "       'CURE END POSITION Θ Collect Result_Dam',\n",
      "       'CURE SPEED Collect Result_Dam',\n",
      "       'CURE STANDBY POSITION X Collect Result_Dam',\n",
      "       'CURE STANDBY POSITION Z Collect Result_Dam',\n",
      "       'CURE STANDBY POSITION Θ Collect Result_Dam',\n",
      "       'CURE START POSITION X Collect Result_Dam',\n",
      "       'CURE START POSITION Z Collect Result_Dam',\n",
      "       ...\n",
      "       'Head Clean Position Y Collect Result_Fill2',\n",
      "       'Head Clean Position Z Collect Result_Fill2',\n",
      "       'Head Purge Position X Collect Result_Fill2',\n",
      "       'Head Purge Position Y Collect Result_Fill2',\n",
      "       'Head Purge Position Z Collect Result_Fill2',\n",
      "       'Machine Tact time Collect Result_Fill2',\n",
      "       'PalletID Collect Result_Fill2', 'Production Qty Collect Result_Fill2',\n",
      "       'Receip No Collect Result_Fill2', 'WorkMode Collect Result_Fill2'],\n",
      "      dtype='object', length=149)\n",
      "Index(['Wip Line_Dam', 'Process Desc._Dam', 'Equipment_Dam',\n",
      "       'Model.Suffix_Dam', 'Workorder_Dam', 'Wip Line_AutoClave',\n",
      "       'Process Desc._AutoClave', 'Equipment_AutoClave',\n",
      "       'Model.Suffix_AutoClave', 'Workorder_AutoClave', 'Wip Line_Fill1',\n",
      "       'Process Desc._Fill1', 'Equipment_Fill1', 'Model.Suffix_Fill1',\n",
      "       'Workorder_Fill1', 'Wip Line_Fill2', 'Process Desc._Fill2',\n",
      "       'Equipment_Fill2', 'Model.Suffix_Fill2', 'Workorder_Fill2', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "filled_na_train_df, num_cols, cat_cols= fill_na_train(missing_values_delete_train_df)\n",
    "print(num_cols)\n",
    "print(cat_cols)\n",
    "filled_na_test_df = fill_na_test(missing_values_delete_test_df, num_cols, cat_cols[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 170 entries, Wip Line_Dam to target\n",
      "dtypes: float64(72), int64(77), object(21)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 170 entries, Set ID to WorkMode Collect Result_Fill2\n",
      "dtypes: float64(72), int64(77), object(21)\n",
      "memory usage: 22.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "describe_data(filled_na_train_df, 'info')\n",
    "describe_data(filled_na_test_df, 'info')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing the target type...\n",
      "Changed target type = int32\n"
     ]
    }
   ],
   "source": [
    "target_type_changed_df = change_target_type(filled_na_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Set ID', 'Wip Line_Dam', 'Process Desc._Dam', 'Equipment_Dam',\n",
      "       'Model.Suffix_Dam', 'Workorder_Dam', 'Wip Line_AutoClave',\n",
      "       'Process Desc._AutoClave', 'Equipment_AutoClave',\n",
      "       'Model.Suffix_AutoClave', 'Workorder_AutoClave', 'Wip Line_Fill1',\n",
      "       'Process Desc._Fill1', 'Equipment_Fill1', 'Model.Suffix_Fill1',\n",
      "       'Workorder_Fill1', 'Wip Line_Fill2', 'Process Desc._Fill2',\n",
      "       'Equipment_Fill2', 'Model.Suffix_Fill2', 'Workorder_Fill2'],\n",
      "      dtype='object')\n",
      "Index(['Wip Line_Dam', 'Process Desc._Dam', 'Equipment_Dam',\n",
      "       'Model.Suffix_Dam', 'Wip Line_AutoClave', 'Process Desc._AutoClave',\n",
      "       'Equipment_AutoClave', 'Model.Suffix_AutoClave', 'Wip Line_Fill1',\n",
      "       'Process Desc._Fill1', 'Equipment_Fill1', 'Model.Suffix_Fill1',\n",
      "       'Wip Line_Fill2', 'Process Desc._Fill2', 'Equipment_Fill2',\n",
      "       'Model.Suffix_Fill2'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 166 entries, Wip Line_Dam to target\n",
      "dtypes: float64(72), int32(17), int64(77)\n",
      "memory usage: 48.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 170 entries, Set ID to WorkMode Collect Result_Fill2\n",
      "dtypes: float64(72), int32(16), int64(77), object(5)\n",
      "memory usage: 21.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(filled_na_test_df.select_dtypes(include=['O']).columns)\n",
    "label_encoded_train_df, label_encoded_test_df = \\\n",
    "    label_encoding_categorical_data(target_type_changed_df, filled_na_test_df)\n",
    "describe_data(label_encoded_train_df, 'info')\n",
    "describe_data(label_encoded_test_df, 'info')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166,)\n",
      "(170,)\n",
      "{'Workorder_Fill2', 'Workorder_Fill1', 'Workorder_AutoClave', 'Set ID', 'Workorder_Dam'}\n",
      "{'Set ID'}\n"
     ]
    }
   ],
   "source": [
    "print(label_encoded_train_df.columns.shape)\n",
    "print(label_encoded_test_df.columns.shape)\n",
    "print(set(label_encoded_test_df.columns) - set(label_encoded_train_df.columns))\n",
    "label_encoded_test_df = label_encoded_test_df.drop(['Workorder_Fill2', 'Workorder_Fill1', 'Workorder_AutoClave', 'Workorder_Dam'], axis = 1)\n",
    "print(set(label_encoded_test_df.columns) - set(label_encoded_train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    40506.000000\n",
      "mean         0.941984\n",
      "std          0.233777\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "describe_data(label_encoded_train_df['target'], 'describe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 166 entries, Wip Line_Dam to target\n",
      "dtypes: float64(106), int32(17), int64(43)\n",
      "memory usage: 48.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 166 entries, Set ID to WorkMode Collect Result_Fill2\n",
      "dtypes: float64(106), int32(16), int64(43), object(1)\n",
      "memory usage: 20.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "outlier_eliminated_train_df, outlier_eliminated_test_df = \\\n",
    "    outliers_processing(label_encoded_train_df, label_encoded_test_df)\n",
    "describe_data(outlier_eliminated_train_df, 'info')\n",
    "describe_data(outlier_eliminated_test_df, 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40506, 166)\n",
      "(17361, 166)\n",
      "(40506, 127)\n",
      "(17361, 127)\n"
     ]
    }
   ],
   "source": [
    "print(outlier_eliminated_train_df.shape)\n",
    "print(outlier_eliminated_test_df.shape)\n",
    "one_unique_dropped_train_df = drop_one_unique_column(outlier_eliminated_train_df)\n",
    "one_unique_dropped_test_df = drop_one_unique_column(outlier_eliminated_test_df)\n",
    "print(one_unique_dropped_train_df.shape)\n",
    "print(one_unique_dropped_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target'}\n",
      "{'Set ID'}\n"
     ]
    }
   ],
   "source": [
    "print(set(one_unique_dropped_train_df.columns) - set(one_unique_dropped_test_df.columns))\n",
    "print(set(one_unique_dropped_test_df.columns) - set(one_unique_dropped_train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 127 entries, Equipment_Dam to target\n",
      "dtypes: float64(119), int32(8)\n",
      "memory usage: 38.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 126 entries, Equipment_Dam to WorkMode Collect Result_Fill2\n",
      "dtypes: float64(119), int32(7)\n",
      "memory usage: 16.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaler = RobustScaler()\n",
    "# scaler = Normalizer()\n",
    "scaled_train_df, scaled_test_df = \\\n",
    "    scaling_processing(one_unique_dropped_train_df, one_unique_dropped_test_df, scaler)\n",
    "\n",
    "print(scaled_train_df.info())\n",
    "print(scaled_test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Saved as use_this_train_data_standard.csv\n",
      "Data Saved as use_this_test_data_standard.csv\n"
     ]
    }
   ],
   "source": [
    "dataframe_to_csv(scaled_train_df, 'use_this_train_data_standard.csv')\n",
    "dataframe_to_csv(scaled_test_df, 'use_this_test_data_standard.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
